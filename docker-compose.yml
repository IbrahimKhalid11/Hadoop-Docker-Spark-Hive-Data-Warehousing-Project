version: '3.7'
services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    container_name: namenode
    environment:
      - CLUSTER_NAME=test-cluster
      - HDFS_CONF_dfs_namenode_safemode_threshold__pct=0

    volumes:
      - hadoop_namenode:/hadoop/dfs/name
      - ./Input_Data:/Input_Data
    ports:
      - "9870:50070" 
    
    networks:
      - hadoop_network


  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    container_name: datanode
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    depends_on:
      - namenode
    ports:
      - "50020:50075"
    networks:
      - hadoop_network



  spark:
    image: bitnami/spark:2.4.5
    container_name: spark
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "8080:8080" 
      - "7077:7077"
    depends_on:
      - namenode
      - datanode
    volumes:
      - ./Input_Data:/Input_Data
      - ./Scripts:/Scripts
    networks:
      - hadoop_network


  spark-worker:
    image: bitnami/spark:2.4.5
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
    depends_on:
      - spark
    networks:
      - hadoop_network

  jupyter:
    image: jupyter/pyspark-notebook:latest
    container_name: jupyter
    environment:
      - HADOOP_USER_NAME=root
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./Input_Data:/Input_Data
      - ./Scripts:/Scripts
    depends_on:
      - spark
    networks:
      - hadoop_network


  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    restart: always
    environment:
      SERVICE_PRECONDITION: "hive-metastore:9083 hive-metastore-postgresql:5432"
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore-postgresql/metastore"
      HIVE_SITE_CONF_hive_metastore_uris: "thrift://hive-metastore:9083"
      CORE_CONF_fs_defaultFS: "hdfs://namenode:8020"
    ports:
      - 10000:10000
      - 10002:10002
    depends_on:
      - hive-metastore
      - hive-metastore-postgresql
    networks:
      - hadoop_network



  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-metastore
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432"
      HIVE_SITE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore-postgresql/metastore"
      HIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName: "org.postgresql.Driver"
      HIVE_SITE_CONF_javax_jdo_option_ConnectionUserName: "hive"
      HIVE_SITE_CONF_javax_jdo_option_ConnectionPassword: "hive"
      HIVE_SITE_CONF_datanucleus_autoCreateSchema: "false"
      HIVE_SITE_CONF_hive_metastore_uris: "thrift://hive-metastore:9083"
    depends_on:
      - namenode
      - datanode
      - hive-metastore-postgresql
    ports:
      - "9083:9083"
    networks:
      - hadoop_network

  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    container_name: hive-metastore-postgresql
    volumes:
      - hive_metastore:/var/lib/postgresql/data
    networks:
      - hadoop_network

volumes:
  hadoop_namenode:
  hadoop_datanode:
  hive_metastore:

networks:
  hadoop_network:
    driver: bridge