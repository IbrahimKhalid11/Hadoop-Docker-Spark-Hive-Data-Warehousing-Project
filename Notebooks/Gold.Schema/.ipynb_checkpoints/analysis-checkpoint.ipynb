{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "139f3a95-e341-4ca0-98d6-4d557263a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6526c580-ce8f-4410-a92c-4781b76deec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc3ab295-e5f9-4fd2-a54e-7da93f0b3c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/06 00:22:42 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Gold Arch\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"/user/hive/warehouse\") \\\n",
    "    .config(\"hive.metastore.uris\", \"thrift://localhost:9083\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f843a38c-be7b-4747-9955-71ceeef105e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "path =\"hdfs:///data/sliver/Fact_Table_parquet\"\n",
    "df = spark.read.parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a754efb3-a7b6-4c75-aaca-8719f2afbf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Edition ID: integer (nullable = true)\n",
      " |-- Country NOC: string (nullable = true)\n",
      " |-- Result ID: integer (nullable = true)\n",
      " |-- Athlete ID: integer (nullable = true)\n",
      " |-- Position: string (nullable = true)\n",
      " |-- Medal Athlete: string (nullable = true)\n",
      " |-- Gold Medals: integer (nullable = true)\n",
      " |-- Silver Medals: integer (nullable = true)\n",
      " |-- Bronze Medals: integer (nullable = true)\n",
      " |-- Total Medals: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb041149-67de-43a4-bbb1-c67778a31a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+----------+--------+-------------+-----------+-------------+-------------+------------+\n",
      "|Edition ID|Country NOC|Result ID|Athlete ID|Position|Medal Athlete|Gold Medals|Silver Medals|Bronze Medals|Total Medals|\n",
      "+----------+-----------+---------+----------+--------+-------------+-----------+-------------+-------------+------------+\n",
      "|        23|        KOR|    40745|      1971|       2|       Silver|         12|            5|           12|          29|\n",
      "|        23|        KOR|    40745|      1972|      15|     No Medal|         12|            5|           12|          29|\n",
      "|        23|        KOR|    40745|      1977|      20|     No Medal|         12|            5|           12|          29|\n",
      "|        23|        KOR|    40788|      1972|       5|     No Medal|         12|            5|           12|          29|\n",
      "|        23|        KOR|    40788|      1971|       5|     No Medal|         12|            5|           12|          29|\n",
      "+----------+-----------+---------+----------+--------+-------------+-----------+-------------+-------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5930a14b-8b17-4df6-9a88-bb3df8b8d339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+------------+------------+------------+\n",
      "|Country NOC|Edition ID|total_gold|total_silver|total_bronze|total_medals|\n",
      "+-----------+----------+----------+------------+------------+------------+\n",
      "|        NED|        40|         1|           2|           3|           6|\n",
      "|        FRA|        41|         0|           0|           1|           1|\n",
      "|        URS|        17|        29|          32|          30|          91|\n",
      "|        ROU|        11|         0|           1|           0|           1|\n",
      "|        GBR|        29|         1|           1|           2|           4|\n",
      "|        ITA|        18|         5|           3|          10|          18|\n",
      "|        ITA|        22|         6|           4|           4|          14|\n",
      "|        FRG|        39|         3|           1|           1|           5|\n",
      "|        CHN|        59|        26|          18|          26|          70|\n",
      "|        GBR|        37|         1|           0|           0|           1|\n",
      "|        FRA|         9|         7|          12|           6|          25|\n",
      "|        ROU|        53|         4|           1|           4|           9|\n",
      "|        ROU|        13|         1|           1|           2|           4|\n",
      "|        ITA|         9|         7|           6|           7|          20|\n",
      "|        URU|         8|         1|           0|           0|           1|\n",
      "|        ZIM|        20|         1|           0|           0|           1|\n",
      "|        FRG|        41|         0|           2|           3|           5|\n",
      "|        GBR|        34|         1|           0|           0|           1|\n",
      "|        ITA|         7|        14|           6|           5|          25|\n",
      "|        FRA|        21|         5|           7|          16|          28|\n",
      "+-----------+----------+----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_unique_results = df.dropDuplicates([\"Country NOC\", \"Edition ID\"])\n",
    "\n",
    "df_medals = df_unique_results.groupBy(\"Country NOC\", \"Edition ID\").agg(\n",
    "    sum(\"Gold Medals\").alias(\"total_gold\"),\n",
    "    sum(\"Silver Medals\").alias(\"total_silver\"),\n",
    "    sum(\"Bronze Medals\").alias(\"total_bronze\")\n",
    ")\n",
    "df_medals = df_medals.withColumn(\"total_medals\", expr(\"total_gold + total_silver + total_bronze\"))\n",
    "\n",
    "# عرض النتائج\n",
    "df_medals.show()\n",
    "\n",
    "# حفظ النتائج في HDFS (الطبقة الذهبية)\n",
    "# df_medals.write.mode(\"overwrite\").parquet(\"hdfs://path_to_gold/medals_per_country_edition\")\n",
    "\n",
    "# customer_churn90.createOrReplaceTempView(\"customer_churn90\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c027a116-9f8b-4a51-a9db-491e28945e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1785"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_medals.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f31e72e-9ab4-40a9-b4db-3cdf03ab6ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country NOC: string (nullable = true)\n",
      " |-- Edition ID: integer (nullable = true)\n",
      " |-- total_gold: long (nullable = true)\n",
      " |-- total_silver: long (nullable = true)\n",
      " |-- total_bronze: long (nullable = true)\n",
      " |-- total_medals: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_medals.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38906bd2-514f-402d-ab40-63b336106a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"hdfs:///data/sliver/Athlete_parquet\"\n",
    "df_bio = spark.read.parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc928947-2e0d-4ee6-bc71-9a61b2d2667e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Athlete ID: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: integer (nullable = true)\n",
      " |-- Born: date (nullable = true)\n",
      " |-- Height: integer (nullable = true)\n",
      " |-- Weight: integer (nullable = true)\n",
      " |-- Nationality: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bio.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c68d9bbd-d2c7-49a7-8c5d-bf4919289d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bio = df_bio.select(\n",
    "    col(\"Athlete ID\").alias(\"bio_athlete_id\"),\n",
    "    \"Name\",\n",
    "    \"Sex\",\n",
    "    \"Born\",\n",
    "    \"Height\",\n",
    "    \"Weight\",\n",
    "    \"Nationality\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f082f0a-cb44-4267-99d1-a6bc85ac1cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_athletes_with_medals = df.join(df_bio, df[\"Athlete ID\"] == df_bio[\"bio_athlete_id\"], \"left_outer\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c5b6ac5-f316-456d-ad86-80acac27c65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+----------+--------+-------------+-----------+-------------+-------------+------------+--------------+--------------+---+----------+------+------+------------------+\n",
      "|Edition ID|Country NOC|Result ID|Athlete ID|Position|Medal Athlete|Gold Medals|Silver Medals|Bronze Medals|Total Medals|bio_athlete_id|          Name|Sex|      Born|Height|Weight|       Nationality|\n",
      "+----------+-----------+---------+----------+--------+-------------+-----------+-------------+-------------+------------+--------------+--------------+---+----------+------+------+------------------+\n",
      "|        23|        KOR|    40745|      1971|       2|       Silver|         12|            5|           12|          29|          1971|Jeong Jae-Heon|  1|1974-06-01|   176|    71| Republic of Korea|\n",
      "|        23|        KOR|    40745|      1972|      15|     No Medal|         12|            5|           12|          29|          1972| Han Seung-Hun|  1|1973-06-11|   171|    62| Republic of Korea|\n",
      "+----------+-----------+---------+----------+--------+-------------+-----------+-------------+-------------+------------+--------------+--------------+---+----------+------+------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_athletes_with_medals.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b49419de-659c-4b2f-84b3-0f7041b64aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------+------------------+-----------------+-------------+---------------+\n",
      "|Country NOC|Edition ID|total_athletes|        avg_height|       avg_weight|male_athletes|female_athletes|\n",
      "+-----------+----------+--------------+------------------+-----------------+-------------+---------------+\n",
      "|        NED|        40|            26|178.26923076923077|73.15384615384616|           13|             13|\n",
      "|        FRA|        41|            44|171.52272727272728|64.95454545454545|           34|             10|\n",
      "|        URS|        17|           501| 175.3692614770459|72.00998003992017|          368|            133|\n",
      "|        ROU|        11|           128|         176.03125|           71.125|          126|              2|\n",
      "|        GBR|        29|            87|176.73684210526315|71.63157894736842|           72|              4|\n",
      "|        ITA|        18|           367| 173.9891008174387|69.21525885558583|          292|             75|\n",
      "|        ITA|        22|           387| 176.6124031007752|  71.328165374677|          310|             77|\n",
      "|        FRG|        39|           125|           175.872|           72.432|           90|             35|\n",
      "|        CHN|        59|           508|174.99606299212599| 67.8484251968504|          204|            304|\n",
      "|        GBR|        37|            66| 173.8181818181818|             71.5|           51|             15|\n",
      "|        FRA|         9|           530|175.71779141104295|70.85276073619632|          436|             53|\n",
      "|        ROU|        53|           176|170.43103448275863|64.07471264367815|           86|             88|\n",
      "|        ROU|        13|           275|175.55597014925374|70.73880597014926|          206|             62|\n",
      "|        ITA|         9|           293|176.10689655172413|71.07586206896552|          268|             22|\n",
      "|        URU|         8|            64|           175.875|71.42857142857143|           56|              0|\n",
      "|        ZIM|        20|            54|172.16666666666666|70.68518518518519|           31|             23|\n",
      "|        FRG|        41|           118| 176.4915254237288|71.82203389830508|           87|             31|\n",
      "|        GBR|        34|            37|             176.0|             71.0|           19|             18|\n",
      "|        ITA|         7|           319|176.28618421052633|71.17763157894737|          300|              4|\n",
      "|        FRA|        21|           368|175.94535519125682| 69.3360655737705|          286|             80|\n",
      "+-----------+----------+--------------+------------------+-----------------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_stats =df_athletes_with_medals.groupBy(\"Country NOC\", \"Edition ID\").agg(\n",
    "    count(\"Athlete ID\").alias(\"total_athletes\"),  # عدد الرياضيين\n",
    "    avg(\"Height\").alias(\"avg_height\"),  # متوسط الطول\n",
    "    avg(\"Weight\").alias(\"avg_weight\"),  # متوسط الوزن\n",
    "    sum(when(df_bio[\"Sex\"] == 1, 1).otherwise(0)).alias(\"male_athletes\"), \n",
    "    sum(when(df_bio[\"Sex\"] == 0, 1).otherwise(0)).alias(\"female_athletes\")\n",
    ")\n",
    "df_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f35537b-0496-4c6b-bc29-a2852b17021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = df_stats.select(\n",
    "    col(\"Country NOC\").alias(\"NOC\"),\n",
    "    col(\"Edition ID\").alias(\"edition_id\"),\n",
    "    \"total_athletes\",\n",
    "    \"avg_height\",\n",
    "    \"avg_weight\",\n",
    "    \"male_athletes\",\n",
    "    \"female_athletes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50bdee6a-c10f-4068-b963-d14811408591",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_stats.join(df_medals, (df_stats[\"edition_id\"] == df_medals[\"Edition ID\"]) & (df_stats[\"NOC\"] == df_medals[\"Country NOC\"])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dd110c6-aeb7-4b2e-8a41-b16d1f4ae788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NOC: string (nullable = true)\n",
      " |-- edition_id: integer (nullable = true)\n",
      " |-- total_athletes: long (nullable = false)\n",
      " |-- avg_height: double (nullable = true)\n",
      " |-- avg_weight: double (nullable = true)\n",
      " |-- male_athletes: long (nullable = true)\n",
      " |-- female_athletes: long (nullable = true)\n",
      " |-- Country NOC: string (nullable = true)\n",
      " |-- Edition ID: integer (nullable = true)\n",
      " |-- total_gold: long (nullable = true)\n",
      " |-- total_silver: long (nullable = true)\n",
      " |-- total_bronze: long (nullable = true)\n",
      " |-- total_medals: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74d9f2e2-7259-4277-a7dc-efe5ea60a9c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `edition_id` cannot be resolved. Did you mean one of the following? [`Edition ID`, `Total Gold`, `Total Bronze`, `Country NOC`, `Total Medals`].;\n'Project [Country NOC#458 AS Country NOC#776, 'edition_id AS Edition ID#777, 'total_athletes AS Total Athletes#778, 'avg_height AS Average Height#779, 'avg_weight AS Average Weight#780, 'male_athletes AS Male Athletes#781, 'female_athletes AS Female Athletes#782, 'total_gold AS Total Gold#783, 'total_silver AS Total Silver#784, 'total_bronze AS Total Bronze#785, 'total_medals AS Total Medals#786]\n+- Project [Country NOC#422 AS Country NOC#458, edition_id#413 AS Edition ID#459, total_athletes#332L AS Total Athletes#460L, avg_height#334 AS Average Height#461, avg_weight#336 AS Average Weight#462, male_athletes#338L AS Male Athletes#463L, female_athletes#340L AS Female Athletes#464L, total_gold#73L AS Total Gold#465L, total_silver#75L AS Total Silver#466L, total_bronze#77L AS Total Bronze#467L, total_medals#83L AS Total Medals#468L]\n   +- Join Inner, ((edition_id#413 = Edition ID#421) AND (NOC#412 = Country NOC#422))\n      :- Project [Country NOC#1 AS NOC#412, Edition ID#0 AS edition_id#413, total_athletes#332L, avg_height#334, avg_weight#336, male_athletes#338L, female_athletes#340L]\n      :  +- Aggregate [Country NOC#1, Edition ID#0], [Country NOC#1, Edition ID#0, count(Athlete ID#3) AS total_athletes#332L, avg(Height#192) AS avg_height#334, avg(Weight#193) AS avg_weight#336, sum(CASE WHEN (Sex#190 = 1) THEN 1 ELSE 0 END) AS male_athletes#338L, sum(CASE WHEN (Sex#190 = 0) THEN 1 ELSE 0 END) AS female_athletes#340L]\n      :     +- Join LeftOuter, (Athlete ID#3 = bio_athlete_id#202)\n      :        :- Relation [Edition ID#0,Country NOC#1,Result ID#2,Athlete ID#3,Position#4,Medal Athlete#5,Gold Medals#6,Silver Medals#7,Bronze Medals#8,Total Medals#9] parquet\n      :        +- Project [Athlete ID#188 AS bio_athlete_id#202, Name#189, Sex#190, Born#191, Height#192, Weight#193, Nationality#194]\n      :           +- Relation [Athlete ID#188,Name#189,Sex#190,Born#191,Height#192,Weight#193,Nationality#194] parquet\n      +- Project [Country NOC#422, Edition ID#421, total_gold#73L, total_silver#75L, total_bronze#77L, ((total_gold#73L + total_silver#75L) + total_bronze#77L) AS total_medals#83L]\n         +- Aggregate [Country NOC#422, Edition ID#421], [Country NOC#422, Edition ID#421, sum(Gold Medals#427) AS total_gold#73L, sum(Silver Medals#428) AS total_silver#75L, sum(Bronze Medals#429) AS total_bronze#77L]\n            +- Deduplicate [Country NOC#422, Edition ID#421]\n               +- Relation [Edition ID#421,Country NOC#422,Result ID#423,Athlete ID#424,Position#425,Medal Athlete#426,Gold Medals#427,Silver Medals#428,Bronze Medals#429,Total Medals#430] parquet\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_final \u001b[38;5;241m=\u001b[39m df_final\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m      2\u001b[0m     col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCountry NOC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCountry NOC\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      3\u001b[0m     col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medition_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEdition ID\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      4\u001b[0m     col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_athletes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Athletes\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      5\u001b[0m     col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_height\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Height\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      6\u001b[0m     col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Weight\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      7\u001b[0m     col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmale_athletes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMale Athletes\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      8\u001b[0m     col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfemale_athletes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFemale Athletes\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      9\u001b[0m     col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_gold\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Gold\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     10\u001b[0m     col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_silver\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Silver\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     11\u001b[0m     col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_bronze\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Bronze\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     12\u001b[0m     col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_medals\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Medals\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m df_final\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m/opt/spark/spark-3.5.5-bin-hadoop3/python/pyspark/sql/dataframe.py:3229\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   3186\u001b[0m \n\u001b[1;32m   3187\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3227\u001b[0m \u001b[38;5;124;03m    +-----+---+\u001b[39;00m\n\u001b[1;32m   3228\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3229\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jcols(\u001b[38;5;241m*\u001b[39mcols))\n\u001b[1;32m   3230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m/opt/spark/spark-3.5.5-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/spark-3.5.5-bin-hadoop3/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `edition_id` cannot be resolved. Did you mean one of the following? [`Edition ID`, `Total Gold`, `Total Bronze`, `Country NOC`, `Total Medals`].;\n'Project [Country NOC#458 AS Country NOC#776, 'edition_id AS Edition ID#777, 'total_athletes AS Total Athletes#778, 'avg_height AS Average Height#779, 'avg_weight AS Average Weight#780, 'male_athletes AS Male Athletes#781, 'female_athletes AS Female Athletes#782, 'total_gold AS Total Gold#783, 'total_silver AS Total Silver#784, 'total_bronze AS Total Bronze#785, 'total_medals AS Total Medals#786]\n+- Project [Country NOC#422 AS Country NOC#458, edition_id#413 AS Edition ID#459, total_athletes#332L AS Total Athletes#460L, avg_height#334 AS Average Height#461, avg_weight#336 AS Average Weight#462, male_athletes#338L AS Male Athletes#463L, female_athletes#340L AS Female Athletes#464L, total_gold#73L AS Total Gold#465L, total_silver#75L AS Total Silver#466L, total_bronze#77L AS Total Bronze#467L, total_medals#83L AS Total Medals#468L]\n   +- Join Inner, ((edition_id#413 = Edition ID#421) AND (NOC#412 = Country NOC#422))\n      :- Project [Country NOC#1 AS NOC#412, Edition ID#0 AS edition_id#413, total_athletes#332L, avg_height#334, avg_weight#336, male_athletes#338L, female_athletes#340L]\n      :  +- Aggregate [Country NOC#1, Edition ID#0], [Country NOC#1, Edition ID#0, count(Athlete ID#3) AS total_athletes#332L, avg(Height#192) AS avg_height#334, avg(Weight#193) AS avg_weight#336, sum(CASE WHEN (Sex#190 = 1) THEN 1 ELSE 0 END) AS male_athletes#338L, sum(CASE WHEN (Sex#190 = 0) THEN 1 ELSE 0 END) AS female_athletes#340L]\n      :     +- Join LeftOuter, (Athlete ID#3 = bio_athlete_id#202)\n      :        :- Relation [Edition ID#0,Country NOC#1,Result ID#2,Athlete ID#3,Position#4,Medal Athlete#5,Gold Medals#6,Silver Medals#7,Bronze Medals#8,Total Medals#9] parquet\n      :        +- Project [Athlete ID#188 AS bio_athlete_id#202, Name#189, Sex#190, Born#191, Height#192, Weight#193, Nationality#194]\n      :           +- Relation [Athlete ID#188,Name#189,Sex#190,Born#191,Height#192,Weight#193,Nationality#194] parquet\n      +- Project [Country NOC#422, Edition ID#421, total_gold#73L, total_silver#75L, total_bronze#77L, ((total_gold#73L + total_silver#75L) + total_bronze#77L) AS total_medals#83L]\n         +- Aggregate [Country NOC#422, Edition ID#421], [Country NOC#422, Edition ID#421, sum(Gold Medals#427) AS total_gold#73L, sum(Silver Medals#428) AS total_silver#75L, sum(Bronze Medals#429) AS total_bronze#77L]\n            +- Deduplicate [Country NOC#422, Edition ID#421]\n               +- Relation [Edition ID#421,Country NOC#422,Result ID#423,Athlete ID#424,Position#425,Medal Athlete#426,Gold Medals#427,Silver Medals#428,Bronze Medals#429,Total Medals#430] parquet\n"
     ]
    }
   ],
   "source": [
    "df_final = df_final.select(\n",
    "    col(\"Country NOC\").alias(\"Country NOC\"),\n",
    "    col(\"edition_id\").alias(\"Edition ID\"),\n",
    "    col(\"total_athletes\").alias(\"Total Athletes\"),\n",
    "    col(\"avg_height\").alias(\"Average Height\"),\n",
    "    col(\"avg_weight\").alias(\"Average Weight\"),\n",
    "    col(\"male_athletes\").alias(\"Male Athletes\"),\n",
    "    col(\"female_athletes\").alias(\"Female Athletes\"),\n",
    "    col(\"total_gold\").alias(\"Total Gold\"),\n",
    "    col(\"total_silver\").alias(\"Total Silver\"),\n",
    "    col(\"total_bronze\").alias(\"Total Bronze\"),\n",
    "    col(\"total_medals\").alias(\"Total Medals\")\n",
    ")\n",
    "\n",
    "df_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94647372-e0a0-4a27-9277-51eaecf66fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final.write.mode(\"overwrite\").parquet(\"hdfs:///data/gold/AnalysisCountryGames_Parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "043184e3-9f7b-4c3c-80fa-3d06faec7092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql(\"SET spark.sql.catalogImplementation=hive\")\n",
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40adfd0f-1e22-4bc9-8f88-1dbce165d278",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "org.apache.hadoop.hive.ql.metadata.HiveException: Unable to fetch table analysiscountrygames_table. Invalid method name: 'get_table'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mmode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msaveAsTable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalysisCountryGames_Table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/spark/spark-3.5.5-bin-hadoop3/python/pyspark/sql/readwriter.py:1586\u001b[0m, in \u001b[0;36mDataFrameWriter.saveAsTable\u001b[0;34m(self, name, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1585\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m-> 1586\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msaveAsTable(name)\n",
      "File \u001b[0;32m/opt/spark/spark-3.5.5-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/spark-3.5.5-bin-hadoop3/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to fetch table analysiscountrygames_table. Invalid method name: 'get_table'"
     ]
    }
   ],
   "source": [
    "df.write.mode(\"overwrite\").saveAsTable(\"AnalysisCountryGames_Table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "857a46a1-5d56-41dc-b8a9-5cfd6a5ed1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/06 00:23:09 WARN HiveConf: HiveConf of name hive.metastore.db.type does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the connection by listing databases\n",
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efcee38e-d75d-4fcc-bab1-83a9bf2ff6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|     gold|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show namespaces;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b72acbe-8ae6-48ad-ae60-4fd0ee3c7bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"create database gold\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae53bbe4-1c0b-45aa-ad6f-cbea0cbdc406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"use gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a29ae0d6-a3b1-49fe-a546-7f7f2dcb0d70",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "org.apache.hadoop.hive.ql.metadata.HiveException: Unable to fetch table product_trends. Invalid method name: 'get_table'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msaveAsTable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgold.product_trends\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/spark/spark-3.5.5-bin-hadoop3/python/pyspark/sql/readwriter.py:1586\u001b[0m, in \u001b[0;36mDataFrameWriter.saveAsTable\u001b[0;34m(self, name, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1585\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m-> 1586\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msaveAsTable(name)\n",
      "File \u001b[0;32m/opt/spark/spark-3.5.5-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/spark-3.5.5-bin-hadoop3/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to fetch table product_trends. Invalid method name: 'get_table'"
     ]
    }
   ],
   "source": [
    "df.write.format(\"hive\").mode(\"overwrite\").saveAsTable(\"gold.product_trends\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7049ed9d-71ba-44f7-aa9f-56539c92cf62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
